{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def spectral_loss(\n",
    "    target_audio,\n",
    "    estimate_audio,\n",
    "    fft_sizes=(2048, 1024, 512, 256, 128, 64),\n",
    "    loss_type=\"L1\",\n",
    "    overlap=0.5,\n",
    "    mag_weight=1.0,\n",
    "    delta_time_weight=0.0,\n",
    "    delta_freq_weight=0.0,\n",
    "    cumsum_freq_weight=0.0,\n",
    "    logmag_weight=0.0,\n",
    "    loudness_weight=0.0,\n",
    "    weights=None,\n",
    "):\n",
    "    \"\"\"Multi-scale spectral loss adapted from https://github.com/magenta/ddsp/blob/main/ddsp/losses.py\n",
    "\n",
    "    Args:\n",
    "        target_audio (torch.tensor): audio target\n",
    "        estimate_audio (torch.tensor): audio estimate\n",
    "        fft_sizes (tuple, optional): fft sizes for multi-scale spectrogram comparison. Defaults to (2048, 1024, 512, 256, 128, 64).\n",
    "        loss_type (str, optional): Can be \"L1\", \"L2\" or \"COSINE\". Defaults to \"L1\".\n",
    "        overlap (float, optional): Overlap for spectrogram computation. Defaults to 0.5.\n",
    "        mag_weight (float, optional): _description_. Defaults to 1.0.\n",
    "        delta_time_weight (float, optional): _description_. Defaults to 0.0.\n",
    "        delta_freq_weight (float, optional): _description_. Defaults to 0.0.\n",
    "        cumsum_freq_weight (float, optional): _description_. Defaults to 0.0.\n",
    "        logmag_weight (float, optional): _description_. Defaults to 0.0.\n",
    "        loudness_weight (float, optional): _description_. Defaults to 0.0.\n",
    "        weights (_type_, optional): _description_. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        torch.tensor: Loss tensor\n",
    "    \"\"\"\n",
    "    loss = 0.0\n",
    "    batch_size, _, n_samples = estimate_audio.shape\n",
    "        \n",
    "    # reshape audio signal for stft function\n",
    "    target_audio = target_audio.reshape((batch_size, n_samples))\n",
    "    estimate_audio = estimate_audio.reshape((batch_size, n_samples))\n",
    "\n",
    "    for fft_size in fft_sizes:\n",
    "        hop_length = int((1 - overlap) * fft_size)\n",
    "        target_mag = torch.abs(\n",
    "            torch.stft(target_audio, fft_size, hop_length, return_complex=True)\n",
    "        )\n",
    "        estimate_mag = torch.abs(\n",
    "            torch.stft(estimate_audio, fft_size, hop_length, return_complex=True)\n",
    "        )\n",
    "\n",
    "        if mag_weight > 0:\n",
    "            loss += mag_weight * mean_difference(\n",
    "                target_mag, estimate_mag, loss_type, weights\n",
    "            )\n",
    "\n",
    "        if delta_time_weight > 0:\n",
    "            target = torch.diff(target_mag, dim=2)\n",
    "            value = torch.diff(estimate_mag, dim=2)\n",
    "            loss += delta_time_weight * mean_difference(\n",
    "                target, value, loss_type, weights\n",
    "            )\n",
    "\n",
    "        if delta_freq_weight > 0:\n",
    "            target = torch.diff(target_mag, dim=1)\n",
    "            value = torch.diff(estimate_mag, dim=1)\n",
    "            loss += delta_freq_weight * mean_difference(\n",
    "                target, value, loss_type, weights\n",
    "            )\n",
    "\n",
    "        if cumsum_freq_weight > 0:\n",
    "            target = torch.cumsum(target_mag, dim=1)\n",
    "            value = torch.cumsum(estimate_mag, dim=1)\n",
    "            loss += cumsum_freq_weight * mean_difference(\n",
    "                target, value, loss_type, weights\n",
    "            )\n",
    "\n",
    "        if logmag_weight > 0:\n",
    "            target = torch.log(target_mag + 1e-6)\n",
    "            value = torch.log(estimate_mag + 1e-6)\n",
    "            loss += logmag_weight * mean_difference(target, value, loss_type, weights)\n",
    "    try:\n",
    "        if loudness_weight > 0:\n",
    "            target = compute_loudness(target, n_fft=2048)\n",
    "            value = compute_loudness(estimate_audio, n_fft=2048)\n",
    "            loss += loudness_weight * mean_difference(target, value, loss_type, weights)\n",
    "    except: \n",
    "        pass\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def mean_difference(target, value, loss_type, weights):\n",
    "    if loss_type == \"L1\":\n",
    "        loss = torch.abs(target - value)\n",
    "    elif loss_type == \"L2\":\n",
    "        loss = (target - value).pow(2)\n",
    "    elif loss_type == \"COSINE\":\n",
    "        target_norm = target.norm(dim=-1, keepdim=True)\n",
    "        value_norm = value.norm(dim=-1, keepdim=True)\n",
    "        similarity = torch.sum(target * value, dim=-1) / (target_norm * value_norm)\n",
    "        loss = 1 - similarity\n",
    "    else:\n",
    "        raise ValueError(\"Invalid loss_type. Use 'L1', 'L2', or 'COSINE'.\")\n",
    "\n",
    "    if weights is not None:\n",
    "        loss = loss * weights\n",
    "\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "def compute_loudness(audio, n_fft):\n",
    "    raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(590028.6250)\n"
     ]
    }
   ],
   "source": [
    "target = torch.randn(1, 1, 160000)  # Example target audio\n",
    "estimate_audio = torch.randn(1, 1, 160000)  # Example audio\n",
    "loss = spectral_loss(\n",
    "    target_audio=target,\n",
    "    estimate_audio=estimate_audio,\n",
    "    loss_type=\"L2\",\n",
    "    mag_weight=1.0,\n",
    "    delta_freq_weight=1.0,\n",
    "    delta_time_weight=1.0,\n",
    "    cumsum_freq_weight=1.0,\n",
    "    logmag_weight=1.0,\n",
    ")\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
